{
  "best_metric": 0.9857298731803894,
  "best_model_checkpoint": "./results\\checkpoint-10536",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 10536,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009491268033409264,
      "grad_norm": 6.781533718109131,
      "learning_rate": 1.8982536066818528e-08,
      "loss": 1.9045,
      "step": 50
    },
    {
      "epoch": 0.018982536066818528,
      "grad_norm": 7.266733646392822,
      "learning_rate": 3.7965072133637056e-08,
      "loss": 1.8964,
      "step": 100
    },
    {
      "epoch": 0.02847380410022779,
      "grad_norm": 7.532681941986084,
      "learning_rate": 5.694760820045559e-08,
      "loss": 1.9081,
      "step": 150
    },
    {
      "epoch": 0.037965072133637055,
      "grad_norm": 6.661933422088623,
      "learning_rate": 7.593014426727411e-08,
      "loss": 1.8962,
      "step": 200
    },
    {
      "epoch": 0.04745634016704632,
      "grad_norm": 4.782284259796143,
      "learning_rate": 9.491268033409265e-08,
      "loss": 1.9219,
      "step": 250
    },
    {
      "epoch": 0.05694760820045558,
      "grad_norm": 6.672574043273926,
      "learning_rate": 1.1389521640091118e-07,
      "loss": 1.8861,
      "step": 300
    },
    {
      "epoch": 0.06643887623386484,
      "grad_norm": 6.003439903259277,
      "learning_rate": 1.328777524677297e-07,
      "loss": 1.9094,
      "step": 350
    },
    {
      "epoch": 0.07593014426727411,
      "grad_norm": 6.052431583404541,
      "learning_rate": 1.5186028853454822e-07,
      "loss": 1.93,
      "step": 400
    },
    {
      "epoch": 0.08542141230068337,
      "grad_norm": 8.3948392868042,
      "learning_rate": 1.7084282460136675e-07,
      "loss": 1.9126,
      "step": 450
    },
    {
      "epoch": 0.09491268033409264,
      "grad_norm": 6.39821720123291,
      "learning_rate": 1.898253606681853e-07,
      "loss": 1.8955,
      "step": 500
    },
    {
      "epoch": 0.1044039483675019,
      "grad_norm": 6.71638298034668,
      "learning_rate": 2.0880789673500383e-07,
      "loss": 1.885,
      "step": 550
    },
    {
      "epoch": 0.11389521640091116,
      "grad_norm": 5.5600361824035645,
      "learning_rate": 2.2779043280182236e-07,
      "loss": 1.8805,
      "step": 600
    },
    {
      "epoch": 0.12338648443432043,
      "grad_norm": 8.162986755371094,
      "learning_rate": 2.4677296886864086e-07,
      "loss": 1.8604,
      "step": 650
    },
    {
      "epoch": 0.13287775246772968,
      "grad_norm": 6.437964916229248,
      "learning_rate": 2.657555049354594e-07,
      "loss": 1.88,
      "step": 700
    },
    {
      "epoch": 0.14236902050113895,
      "grad_norm": 6.0843186378479,
      "learning_rate": 2.847380410022779e-07,
      "loss": 1.8939,
      "step": 750
    },
    {
      "epoch": 0.15186028853454822,
      "grad_norm": 6.881246566772461,
      "learning_rate": 3.0372057706909645e-07,
      "loss": 1.8767,
      "step": 800
    },
    {
      "epoch": 0.16135155656795747,
      "grad_norm": 7.419300556182861,
      "learning_rate": 3.22703113135915e-07,
      "loss": 1.8718,
      "step": 850
    },
    {
      "epoch": 0.17084282460136674,
      "grad_norm": 5.736841678619385,
      "learning_rate": 3.416856492027335e-07,
      "loss": 1.8611,
      "step": 900
    },
    {
      "epoch": 0.180334092634776,
      "grad_norm": 6.552237033843994,
      "learning_rate": 3.6066818526955203e-07,
      "loss": 1.8646,
      "step": 950
    },
    {
      "epoch": 0.18982536066818528,
      "grad_norm": 7.06653356552124,
      "learning_rate": 3.796507213363706e-07,
      "loss": 1.8617,
      "step": 1000
    },
    {
      "epoch": 0.19931662870159453,
      "grad_norm": 6.590609073638916,
      "learning_rate": 3.9863325740318914e-07,
      "loss": 1.8511,
      "step": 1050
    },
    {
      "epoch": 0.2088078967350038,
      "grad_norm": 8.35180950164795,
      "learning_rate": 4.1761579347000767e-07,
      "loss": 1.8463,
      "step": 1100
    },
    {
      "epoch": 0.21829916476841307,
      "grad_norm": 7.201739311218262,
      "learning_rate": 4.365983295368262e-07,
      "loss": 1.8574,
      "step": 1150
    },
    {
      "epoch": 0.22779043280182232,
      "grad_norm": 6.361911773681641,
      "learning_rate": 4.555808656036447e-07,
      "loss": 1.8475,
      "step": 1200
    },
    {
      "epoch": 0.2372817008352316,
      "grad_norm": 8.124828338623047,
      "learning_rate": 4.7456340167046325e-07,
      "loss": 1.8672,
      "step": 1250
    },
    {
      "epoch": 0.24677296886864086,
      "grad_norm": 7.5856804847717285,
      "learning_rate": 4.935459377372817e-07,
      "loss": 1.8176,
      "step": 1300
    },
    {
      "epoch": 0.25626423690205014,
      "grad_norm": 5.980137825012207,
      "learning_rate": 5.125284738041003e-07,
      "loss": 1.8091,
      "step": 1350
    },
    {
      "epoch": 0.26575550493545935,
      "grad_norm": 7.428492069244385,
      "learning_rate": 5.315110098709188e-07,
      "loss": 1.8369,
      "step": 1400
    },
    {
      "epoch": 0.2752467729688686,
      "grad_norm": 6.454822063446045,
      "learning_rate": 5.504935459377373e-07,
      "loss": 1.8164,
      "step": 1450
    },
    {
      "epoch": 0.2847380410022779,
      "grad_norm": 6.958491325378418,
      "learning_rate": 5.694760820045558e-07,
      "loss": 1.7924,
      "step": 1500
    },
    {
      "epoch": 0.29422930903568717,
      "grad_norm": 6.073852062225342,
      "learning_rate": 5.884586180713744e-07,
      "loss": 1.7821,
      "step": 1550
    },
    {
      "epoch": 0.30372057706909644,
      "grad_norm": 6.060319423675537,
      "learning_rate": 6.074411541381929e-07,
      "loss": 1.8076,
      "step": 1600
    },
    {
      "epoch": 0.3132118451025057,
      "grad_norm": 6.922138214111328,
      "learning_rate": 6.264236902050115e-07,
      "loss": 1.7945,
      "step": 1650
    },
    {
      "epoch": 0.32270311313591493,
      "grad_norm": 8.807982444763184,
      "learning_rate": 6.4540622627183e-07,
      "loss": 1.7946,
      "step": 1700
    },
    {
      "epoch": 0.3321943811693242,
      "grad_norm": 8.394856452941895,
      "learning_rate": 6.643887623386485e-07,
      "loss": 1.7592,
      "step": 1750
    },
    {
      "epoch": 0.3416856492027335,
      "grad_norm": 7.335812568664551,
      "learning_rate": 6.83371298405467e-07,
      "loss": 1.7673,
      "step": 1800
    },
    {
      "epoch": 0.35117691723614275,
      "grad_norm": 5.55386209487915,
      "learning_rate": 7.023538344722855e-07,
      "loss": 1.7621,
      "step": 1850
    },
    {
      "epoch": 0.360668185269552,
      "grad_norm": 6.270002841949463,
      "learning_rate": 7.213363705391041e-07,
      "loss": 1.7644,
      "step": 1900
    },
    {
      "epoch": 0.3701594533029613,
      "grad_norm": 6.1040472984313965,
      "learning_rate": 7.403189066059226e-07,
      "loss": 1.742,
      "step": 1950
    },
    {
      "epoch": 0.37965072133637057,
      "grad_norm": 7.086050987243652,
      "learning_rate": 7.593014426727412e-07,
      "loss": 1.7636,
      "step": 2000
    },
    {
      "epoch": 0.3891419893697798,
      "grad_norm": 6.752301216125488,
      "learning_rate": 7.782839787395596e-07,
      "loss": 1.7136,
      "step": 2050
    },
    {
      "epoch": 0.39863325740318906,
      "grad_norm": 7.262324333190918,
      "learning_rate": 7.972665148063783e-07,
      "loss": 1.7126,
      "step": 2100
    },
    {
      "epoch": 0.40812452543659833,
      "grad_norm": 6.354671478271484,
      "learning_rate": 8.162490508731967e-07,
      "loss": 1.768,
      "step": 2150
    },
    {
      "epoch": 0.4176157934700076,
      "grad_norm": 6.536283016204834,
      "learning_rate": 8.352315869400153e-07,
      "loss": 1.7133,
      "step": 2200
    },
    {
      "epoch": 0.4271070615034169,
      "grad_norm": 5.915724277496338,
      "learning_rate": 8.542141230068338e-07,
      "loss": 1.6628,
      "step": 2250
    },
    {
      "epoch": 0.43659832953682615,
      "grad_norm": 6.443665981292725,
      "learning_rate": 8.731966590736524e-07,
      "loss": 1.6854,
      "step": 2300
    },
    {
      "epoch": 0.44608959757023536,
      "grad_norm": 6.667612552642822,
      "learning_rate": 8.921791951404708e-07,
      "loss": 1.6875,
      "step": 2350
    },
    {
      "epoch": 0.45558086560364464,
      "grad_norm": 5.933440208435059,
      "learning_rate": 9.111617312072894e-07,
      "loss": 1.6823,
      "step": 2400
    },
    {
      "epoch": 0.4650721336370539,
      "grad_norm": 5.7874932289123535,
      "learning_rate": 9.301442672741079e-07,
      "loss": 1.6848,
      "step": 2450
    },
    {
      "epoch": 0.4745634016704632,
      "grad_norm": 6.891671180725098,
      "learning_rate": 9.491268033409265e-07,
      "loss": 1.665,
      "step": 2500
    },
    {
      "epoch": 0.48405466970387245,
      "grad_norm": 6.06433629989624,
      "learning_rate": 9.68109339407745e-07,
      "loss": 1.6278,
      "step": 2550
    },
    {
      "epoch": 0.4935459377372817,
      "grad_norm": 6.95818567276001,
      "learning_rate": 9.870918754745634e-07,
      "loss": 1.6393,
      "step": 2600
    },
    {
      "epoch": 0.503037205770691,
      "grad_norm": 6.200324535369873,
      "learning_rate": 1.006074411541382e-06,
      "loss": 1.6185,
      "step": 2650
    },
    {
      "epoch": 0.5125284738041003,
      "grad_norm": 6.010601043701172,
      "learning_rate": 1.0250569476082005e-06,
      "loss": 1.5811,
      "step": 2700
    },
    {
      "epoch": 0.5220197418375095,
      "grad_norm": 8.4634428024292,
      "learning_rate": 1.044039483675019e-06,
      "loss": 1.599,
      "step": 2750
    },
    {
      "epoch": 0.5315110098709187,
      "grad_norm": 5.99493408203125,
      "learning_rate": 1.0630220197418376e-06,
      "loss": 1.6122,
      "step": 2800
    },
    {
      "epoch": 0.541002277904328,
      "grad_norm": 5.33767032623291,
      "learning_rate": 1.082004555808656e-06,
      "loss": 1.6236,
      "step": 2850
    },
    {
      "epoch": 0.5504935459377372,
      "grad_norm": 5.12007999420166,
      "learning_rate": 1.1009870918754746e-06,
      "loss": 1.604,
      "step": 2900
    },
    {
      "epoch": 0.5599848139711465,
      "grad_norm": 6.034331321716309,
      "learning_rate": 1.1199696279422931e-06,
      "loss": 1.6182,
      "step": 2950
    },
    {
      "epoch": 0.5694760820045558,
      "grad_norm": 5.838982582092285,
      "learning_rate": 1.1389521640091117e-06,
      "loss": 1.5432,
      "step": 3000
    },
    {
      "epoch": 0.5789673500379651,
      "grad_norm": 5.8897223472595215,
      "learning_rate": 1.1579347000759302e-06,
      "loss": 1.5486,
      "step": 3050
    },
    {
      "epoch": 0.5884586180713743,
      "grad_norm": 5.698884963989258,
      "learning_rate": 1.1769172361427487e-06,
      "loss": 1.5531,
      "step": 3100
    },
    {
      "epoch": 0.5979498861047836,
      "grad_norm": 6.753091335296631,
      "learning_rate": 1.1958997722095673e-06,
      "loss": 1.526,
      "step": 3150
    },
    {
      "epoch": 0.6074411541381929,
      "grad_norm": 5.610910415649414,
      "learning_rate": 1.2148823082763858e-06,
      "loss": 1.497,
      "step": 3200
    },
    {
      "epoch": 0.6169324221716022,
      "grad_norm": 5.57576847076416,
      "learning_rate": 1.2338648443432043e-06,
      "loss": 1.4717,
      "step": 3250
    },
    {
      "epoch": 0.6264236902050114,
      "grad_norm": 5.431122303009033,
      "learning_rate": 1.252847380410023e-06,
      "loss": 1.5459,
      "step": 3300
    },
    {
      "epoch": 0.6359149582384207,
      "grad_norm": 5.800791263580322,
      "learning_rate": 1.2718299164768414e-06,
      "loss": 1.4849,
      "step": 3350
    },
    {
      "epoch": 0.6454062262718299,
      "grad_norm": 6.740391254425049,
      "learning_rate": 1.29081245254366e-06,
      "loss": 1.547,
      "step": 3400
    },
    {
      "epoch": 0.6548974943052391,
      "grad_norm": 6.926745414733887,
      "learning_rate": 1.3097949886104786e-06,
      "loss": 1.6048,
      "step": 3450
    },
    {
      "epoch": 0.6643887623386484,
      "grad_norm": 6.111976146697998,
      "learning_rate": 1.328777524677297e-06,
      "loss": 1.5252,
      "step": 3500
    },
    {
      "epoch": 0.6738800303720577,
      "grad_norm": 7.135305881500244,
      "learning_rate": 1.3477600607441155e-06,
      "loss": 1.5267,
      "step": 3550
    },
    {
      "epoch": 0.683371298405467,
      "grad_norm": 6.208704948425293,
      "learning_rate": 1.366742596810934e-06,
      "loss": 1.4807,
      "step": 3600
    },
    {
      "epoch": 0.6928625664388762,
      "grad_norm": 7.233537673950195,
      "learning_rate": 1.3857251328777527e-06,
      "loss": 1.5276,
      "step": 3650
    },
    {
      "epoch": 0.7023538344722855,
      "grad_norm": 5.419264793395996,
      "learning_rate": 1.404707668944571e-06,
      "loss": 1.4692,
      "step": 3700
    },
    {
      "epoch": 0.7118451025056948,
      "grad_norm": 5.498508453369141,
      "learning_rate": 1.4236902050113896e-06,
      "loss": 1.4666,
      "step": 3750
    },
    {
      "epoch": 0.721336370539104,
      "grad_norm": 5.954653263092041,
      "learning_rate": 1.4426727410782081e-06,
      "loss": 1.4721,
      "step": 3800
    },
    {
      "epoch": 0.7308276385725133,
      "grad_norm": 5.4256205558776855,
      "learning_rate": 1.4616552771450269e-06,
      "loss": 1.4695,
      "step": 3850
    },
    {
      "epoch": 0.7403189066059226,
      "grad_norm": 5.338573932647705,
      "learning_rate": 1.4806378132118452e-06,
      "loss": 1.498,
      "step": 3900
    },
    {
      "epoch": 0.7498101746393319,
      "grad_norm": 5.638768672943115,
      "learning_rate": 1.4996203492786637e-06,
      "loss": 1.4868,
      "step": 3950
    },
    {
      "epoch": 0.7593014426727411,
      "grad_norm": 6.837031364440918,
      "learning_rate": 1.5186028853454824e-06,
      "loss": 1.4734,
      "step": 4000
    },
    {
      "epoch": 0.7687927107061503,
      "grad_norm": 5.757120609283447,
      "learning_rate": 1.537585421412301e-06,
      "loss": 1.4525,
      "step": 4050
    },
    {
      "epoch": 0.7782839787395596,
      "grad_norm": 4.101736068725586,
      "learning_rate": 1.5565679574791193e-06,
      "loss": 1.4537,
      "step": 4100
    },
    {
      "epoch": 0.7877752467729688,
      "grad_norm": 5.155644416809082,
      "learning_rate": 1.5755504935459378e-06,
      "loss": 1.4402,
      "step": 4150
    },
    {
      "epoch": 0.7972665148063781,
      "grad_norm": 5.0357770919799805,
      "learning_rate": 1.5945330296127566e-06,
      "loss": 1.3498,
      "step": 4200
    },
    {
      "epoch": 0.8067577828397874,
      "grad_norm": 5.147688388824463,
      "learning_rate": 1.6135155656795749e-06,
      "loss": 1.4572,
      "step": 4250
    },
    {
      "epoch": 0.8162490508731967,
      "grad_norm": 8.150679588317871,
      "learning_rate": 1.6324981017463934e-06,
      "loss": 1.4161,
      "step": 4300
    },
    {
      "epoch": 0.8257403189066059,
      "grad_norm": 5.87668514251709,
      "learning_rate": 1.651480637813212e-06,
      "loss": 1.45,
      "step": 4350
    },
    {
      "epoch": 0.8352315869400152,
      "grad_norm": 6.621004104614258,
      "learning_rate": 1.6704631738800307e-06,
      "loss": 1.4432,
      "step": 4400
    },
    {
      "epoch": 0.8447228549734245,
      "grad_norm": 5.4572649002075195,
      "learning_rate": 1.689445709946849e-06,
      "loss": 1.4434,
      "step": 4450
    },
    {
      "epoch": 0.8542141230068337,
      "grad_norm": 5.729280948638916,
      "learning_rate": 1.7084282460136675e-06,
      "loss": 1.4217,
      "step": 4500
    },
    {
      "epoch": 0.863705391040243,
      "grad_norm": 6.268518447875977,
      "learning_rate": 1.727410782080486e-06,
      "loss": 1.3319,
      "step": 4550
    },
    {
      "epoch": 0.8731966590736523,
      "grad_norm": 5.37209939956665,
      "learning_rate": 1.7463933181473048e-06,
      "loss": 1.4134,
      "step": 4600
    },
    {
      "epoch": 0.8826879271070615,
      "grad_norm": 5.681509494781494,
      "learning_rate": 1.765375854214123e-06,
      "loss": 1.4411,
      "step": 4650
    },
    {
      "epoch": 0.8921791951404707,
      "grad_norm": 5.10499382019043,
      "learning_rate": 1.7843583902809416e-06,
      "loss": 1.3592,
      "step": 4700
    },
    {
      "epoch": 0.90167046317388,
      "grad_norm": 5.10657262802124,
      "learning_rate": 1.8033409263477604e-06,
      "loss": 1.3716,
      "step": 4750
    },
    {
      "epoch": 0.9111617312072893,
      "grad_norm": 5.1439666748046875,
      "learning_rate": 1.8223234624145789e-06,
      "loss": 1.3919,
      "step": 4800
    },
    {
      "epoch": 0.9206529992406985,
      "grad_norm": 6.941906452178955,
      "learning_rate": 1.8413059984813972e-06,
      "loss": 1.3528,
      "step": 4850
    },
    {
      "epoch": 0.9301442672741078,
      "grad_norm": 4.646480560302734,
      "learning_rate": 1.8602885345482157e-06,
      "loss": 1.3679,
      "step": 4900
    },
    {
      "epoch": 0.9396355353075171,
      "grad_norm": 4.150309085845947,
      "learning_rate": 1.8792710706150345e-06,
      "loss": 1.354,
      "step": 4950
    },
    {
      "epoch": 0.9491268033409264,
      "grad_norm": 6.288318157196045,
      "learning_rate": 1.898253606681853e-06,
      "loss": 1.4323,
      "step": 5000
    },
    {
      "epoch": 0.9586180713743356,
      "grad_norm": 5.229976177215576,
      "learning_rate": 1.9172361427486713e-06,
      "loss": 1.3896,
      "step": 5050
    },
    {
      "epoch": 0.9681093394077449,
      "grad_norm": 5.8981852531433105,
      "learning_rate": 1.93621867881549e-06,
      "loss": 1.3476,
      "step": 5100
    },
    {
      "epoch": 0.9776006074411542,
      "grad_norm": 7.595494747161865,
      "learning_rate": 1.9552012148823084e-06,
      "loss": 1.4024,
      "step": 5150
    },
    {
      "epoch": 0.9870918754745635,
      "grad_norm": 7.758345127105713,
      "learning_rate": 1.974183750949127e-06,
      "loss": 1.3631,
      "step": 5200
    },
    {
      "epoch": 0.9965831435079726,
      "grad_norm": 5.87869930267334,
      "learning_rate": 1.9931662870159454e-06,
      "loss": 1.3904,
      "step": 5250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5406662237828604,
      "eval_f1": 0.19993373817835974,
      "eval_loss": 1.3035351037979126,
      "eval_precision": 0.3118988727776137,
      "eval_recall": 0.257349917072959,
      "eval_runtime": 190.9898,
      "eval_samples_per_second": 55.17,
      "eval_steps_per_second": 6.901,
      "step": 5268
    },
    {
      "epoch": 1.006074411541382,
      "grad_norm": 5.436108112335205,
      "learning_rate": 2.012148823082764e-06,
      "loss": 1.3635,
      "step": 5300
    },
    {
      "epoch": 1.0155656795747912,
      "grad_norm": 6.2826313972473145,
      "learning_rate": 2.0311313591495825e-06,
      "loss": 1.3878,
      "step": 5350
    },
    {
      "epoch": 1.0250569476082005,
      "grad_norm": 5.39915132522583,
      "learning_rate": 2.050113895216401e-06,
      "loss": 1.3445,
      "step": 5400
    },
    {
      "epoch": 1.0345482156416097,
      "grad_norm": 5.8375630378723145,
      "learning_rate": 2.0690964312832195e-06,
      "loss": 1.3352,
      "step": 5450
    },
    {
      "epoch": 1.044039483675019,
      "grad_norm": 5.015005588531494,
      "learning_rate": 2.088078967350038e-06,
      "loss": 1.3592,
      "step": 5500
    },
    {
      "epoch": 1.0535307517084282,
      "grad_norm": 6.2365288734436035,
      "learning_rate": 2.1070615034168566e-06,
      "loss": 1.312,
      "step": 5550
    },
    {
      "epoch": 1.0630220197418374,
      "grad_norm": 7.182867527008057,
      "learning_rate": 2.126044039483675e-06,
      "loss": 1.3133,
      "step": 5600
    },
    {
      "epoch": 1.0725132877752468,
      "grad_norm": 6.894881248474121,
      "learning_rate": 2.1450265755504936e-06,
      "loss": 1.3833,
      "step": 5650
    },
    {
      "epoch": 1.082004555808656,
      "grad_norm": 4.371942520141602,
      "learning_rate": 2.164009111617312e-06,
      "loss": 1.3228,
      "step": 5700
    },
    {
      "epoch": 1.0914958238420653,
      "grad_norm": 6.1741943359375,
      "learning_rate": 2.1829916476841307e-06,
      "loss": 1.2974,
      "step": 5750
    },
    {
      "epoch": 1.1009870918754745,
      "grad_norm": 6.626845836639404,
      "learning_rate": 2.2019741837509492e-06,
      "loss": 1.23,
      "step": 5800
    },
    {
      "epoch": 1.1104783599088839,
      "grad_norm": 5.182972431182861,
      "learning_rate": 2.2209567198177678e-06,
      "loss": 1.2712,
      "step": 5850
    },
    {
      "epoch": 1.119969627942293,
      "grad_norm": 8.018512725830078,
      "learning_rate": 2.2399392558845863e-06,
      "loss": 1.2832,
      "step": 5900
    },
    {
      "epoch": 1.1294608959757024,
      "grad_norm": 5.832951068878174,
      "learning_rate": 2.258921791951405e-06,
      "loss": 1.3009,
      "step": 5950
    },
    {
      "epoch": 1.1389521640091116,
      "grad_norm": 9.562484741210938,
      "learning_rate": 2.2779043280182233e-06,
      "loss": 1.2876,
      "step": 6000
    },
    {
      "epoch": 1.148443432042521,
      "grad_norm": 4.55044412612915,
      "learning_rate": 2.296886864085042e-06,
      "loss": 1.2829,
      "step": 6050
    },
    {
      "epoch": 1.1579347000759301,
      "grad_norm": 6.148865222930908,
      "learning_rate": 2.3158694001518604e-06,
      "loss": 1.3325,
      "step": 6100
    },
    {
      "epoch": 1.1674259681093395,
      "grad_norm": 5.95477819442749,
      "learning_rate": 2.334851936218679e-06,
      "loss": 1.2746,
      "step": 6150
    },
    {
      "epoch": 1.1769172361427487,
      "grad_norm": 7.444988250732422,
      "learning_rate": 2.3538344722854975e-06,
      "loss": 1.2723,
      "step": 6200
    },
    {
      "epoch": 1.1864085041761578,
      "grad_norm": 4.726620197296143,
      "learning_rate": 2.372817008352316e-06,
      "loss": 1.3168,
      "step": 6250
    },
    {
      "epoch": 1.1958997722095672,
      "grad_norm": 4.022007465362549,
      "learning_rate": 2.3917995444191345e-06,
      "loss": 1.2664,
      "step": 6300
    },
    {
      "epoch": 1.2053910402429764,
      "grad_norm": 7.383367538452148,
      "learning_rate": 2.410782080485953e-06,
      "loss": 1.304,
      "step": 6350
    },
    {
      "epoch": 1.2148823082763858,
      "grad_norm": 7.247731685638428,
      "learning_rate": 2.4297646165527716e-06,
      "loss": 1.2088,
      "step": 6400
    },
    {
      "epoch": 1.224373576309795,
      "grad_norm": 6.626587390899658,
      "learning_rate": 2.44874715261959e-06,
      "loss": 1.2823,
      "step": 6450
    },
    {
      "epoch": 1.2338648443432043,
      "grad_norm": 5.657367706298828,
      "learning_rate": 2.4677296886864086e-06,
      "loss": 1.2416,
      "step": 6500
    },
    {
      "epoch": 1.2433561123766135,
      "grad_norm": 5.688270568847656,
      "learning_rate": 2.486712224753227e-06,
      "loss": 1.2169,
      "step": 6550
    },
    {
      "epoch": 1.2528473804100229,
      "grad_norm": 5.919439792633057,
      "learning_rate": 2.505694760820046e-06,
      "loss": 1.2919,
      "step": 6600
    },
    {
      "epoch": 1.262338648443432,
      "grad_norm": 11.849943161010742,
      "learning_rate": 2.524677296886864e-06,
      "loss": 1.2256,
      "step": 6650
    },
    {
      "epoch": 1.2718299164768414,
      "grad_norm": 7.510192394256592,
      "learning_rate": 2.5436598329536827e-06,
      "loss": 1.2183,
      "step": 6700
    },
    {
      "epoch": 1.2813211845102506,
      "grad_norm": 4.747722625732422,
      "learning_rate": 2.5626423690205017e-06,
      "loss": 1.269,
      "step": 6750
    },
    {
      "epoch": 1.2908124525436597,
      "grad_norm": 5.539303302764893,
      "learning_rate": 2.58162490508732e-06,
      "loss": 1.1963,
      "step": 6800
    },
    {
      "epoch": 1.300303720577069,
      "grad_norm": 8.497318267822266,
      "learning_rate": 2.6006074411541383e-06,
      "loss": 1.2793,
      "step": 6850
    },
    {
      "epoch": 1.3097949886104785,
      "grad_norm": 4.934028625488281,
      "learning_rate": 2.6195899772209573e-06,
      "loss": 1.1998,
      "step": 6900
    },
    {
      "epoch": 1.3192862566438877,
      "grad_norm": 7.271026134490967,
      "learning_rate": 2.6385725132877754e-06,
      "loss": 1.2192,
      "step": 6950
    },
    {
      "epoch": 1.3287775246772968,
      "grad_norm": 4.72705602645874,
      "learning_rate": 2.657555049354594e-06,
      "loss": 1.2457,
      "step": 7000
    },
    {
      "epoch": 1.3382687927107062,
      "grad_norm": 5.830032825469971,
      "learning_rate": 2.6765375854214124e-06,
      "loss": 1.2299,
      "step": 7050
    },
    {
      "epoch": 1.3477600607441154,
      "grad_norm": 8.889971733093262,
      "learning_rate": 2.695520121488231e-06,
      "loss": 1.3395,
      "step": 7100
    },
    {
      "epoch": 1.3572513287775247,
      "grad_norm": 8.790315628051758,
      "learning_rate": 2.71450265755505e-06,
      "loss": 1.2323,
      "step": 7150
    },
    {
      "epoch": 1.366742596810934,
      "grad_norm": 8.498093605041504,
      "learning_rate": 2.733485193621868e-06,
      "loss": 1.2371,
      "step": 7200
    },
    {
      "epoch": 1.3762338648443433,
      "grad_norm": 7.1971917152404785,
      "learning_rate": 2.7524677296886865e-06,
      "loss": 1.2715,
      "step": 7250
    },
    {
      "epoch": 1.3857251328777525,
      "grad_norm": 7.510544776916504,
      "learning_rate": 2.7714502657555055e-06,
      "loss": 1.1283,
      "step": 7300
    },
    {
      "epoch": 1.3952164009111616,
      "grad_norm": 7.349056720733643,
      "learning_rate": 2.7904328018223236e-06,
      "loss": 1.195,
      "step": 7350
    },
    {
      "epoch": 1.404707668944571,
      "grad_norm": 6.695216655731201,
      "learning_rate": 2.809415337889142e-06,
      "loss": 1.199,
      "step": 7400
    },
    {
      "epoch": 1.4141989369779804,
      "grad_norm": 4.827058792114258,
      "learning_rate": 2.828397873955961e-06,
      "loss": 1.1474,
      "step": 7450
    },
    {
      "epoch": 1.4236902050113895,
      "grad_norm": 4.820675373077393,
      "learning_rate": 2.847380410022779e-06,
      "loss": 1.2232,
      "step": 7500
    },
    {
      "epoch": 1.4331814730447987,
      "grad_norm": 4.273978233337402,
      "learning_rate": 2.8663629460895977e-06,
      "loss": 1.2519,
      "step": 7550
    },
    {
      "epoch": 1.442672741078208,
      "grad_norm": 8.836321830749512,
      "learning_rate": 2.8853454821564162e-06,
      "loss": 1.1708,
      "step": 7600
    },
    {
      "epoch": 1.4521640091116172,
      "grad_norm": 7.872626304626465,
      "learning_rate": 2.9043280182232348e-06,
      "loss": 1.1577,
      "step": 7650
    },
    {
      "epoch": 1.4616552771450266,
      "grad_norm": 11.652875900268555,
      "learning_rate": 2.9233105542900537e-06,
      "loss": 1.2186,
      "step": 7700
    },
    {
      "epoch": 1.4711465451784358,
      "grad_norm": 7.26560640335083,
      "learning_rate": 2.942293090356872e-06,
      "loss": 1.1554,
      "step": 7750
    },
    {
      "epoch": 1.4806378132118452,
      "grad_norm": 4.772738933563232,
      "learning_rate": 2.9612756264236903e-06,
      "loss": 1.2332,
      "step": 7800
    },
    {
      "epoch": 1.4901290812452543,
      "grad_norm": 8.238712310791016,
      "learning_rate": 2.9802581624905093e-06,
      "loss": 1.1547,
      "step": 7850
    },
    {
      "epoch": 1.4996203492786635,
      "grad_norm": 7.161807060241699,
      "learning_rate": 2.9992406985573274e-06,
      "loss": 1.1491,
      "step": 7900
    },
    {
      "epoch": 1.5091116173120729,
      "grad_norm": 9.07370662689209,
      "learning_rate": 3.018223234624146e-06,
      "loss": 1.2157,
      "step": 7950
    },
    {
      "epoch": 1.5186028853454823,
      "grad_norm": 10.924820899963379,
      "learning_rate": 3.037205770690965e-06,
      "loss": 1.1609,
      "step": 8000
    },
    {
      "epoch": 1.5280941533788914,
      "grad_norm": 9.03322696685791,
      "learning_rate": 3.056188306757783e-06,
      "loss": 1.1391,
      "step": 8050
    },
    {
      "epoch": 1.5375854214123006,
      "grad_norm": 9.818289756774902,
      "learning_rate": 3.075170842824602e-06,
      "loss": 1.1589,
      "step": 8100
    },
    {
      "epoch": 1.54707668944571,
      "grad_norm": 12.107394218444824,
      "learning_rate": 3.09415337889142e-06,
      "loss": 1.103,
      "step": 8150
    },
    {
      "epoch": 1.5565679574791194,
      "grad_norm": 8.504629135131836,
      "learning_rate": 3.1131359149582386e-06,
      "loss": 1.1712,
      "step": 8200
    },
    {
      "epoch": 1.5660592255125285,
      "grad_norm": 8.453020095825195,
      "learning_rate": 3.1321184510250575e-06,
      "loss": 1.134,
      "step": 8250
    },
    {
      "epoch": 1.5755504935459377,
      "grad_norm": 10.963301658630371,
      "learning_rate": 3.1511009870918756e-06,
      "loss": 1.1265,
      "step": 8300
    },
    {
      "epoch": 1.585041761579347,
      "grad_norm": 11.298511505126953,
      "learning_rate": 3.170083523158694e-06,
      "loss": 1.1353,
      "step": 8350
    },
    {
      "epoch": 1.5945330296127562,
      "grad_norm": 8.937603950500488,
      "learning_rate": 3.189066059225513e-06,
      "loss": 1.1502,
      "step": 8400
    },
    {
      "epoch": 1.6040242976461654,
      "grad_norm": 6.993666172027588,
      "learning_rate": 3.208048595292331e-06,
      "loss": 1.1709,
      "step": 8450
    },
    {
      "epoch": 1.6135155656795748,
      "grad_norm": 8.333600997924805,
      "learning_rate": 3.2270311313591497e-06,
      "loss": 1.1268,
      "step": 8500
    },
    {
      "epoch": 1.6230068337129842,
      "grad_norm": 9.15424919128418,
      "learning_rate": 3.2460136674259683e-06,
      "loss": 1.1556,
      "step": 8550
    },
    {
      "epoch": 1.6324981017463933,
      "grad_norm": 17.349645614624023,
      "learning_rate": 3.264996203492787e-06,
      "loss": 1.1123,
      "step": 8600
    },
    {
      "epoch": 1.6419893697798025,
      "grad_norm": 8.872285842895508,
      "learning_rate": 3.2839787395596057e-06,
      "loss": 1.1356,
      "step": 8650
    },
    {
      "epoch": 1.6514806378132119,
      "grad_norm": 8.16823673248291,
      "learning_rate": 3.302961275626424e-06,
      "loss": 1.0176,
      "step": 8700
    },
    {
      "epoch": 1.6609719058466212,
      "grad_norm": 7.7541117668151855,
      "learning_rate": 3.3219438116932424e-06,
      "loss": 1.1424,
      "step": 8750
    },
    {
      "epoch": 1.6704631738800304,
      "grad_norm": 6.881016254425049,
      "learning_rate": 3.3409263477600613e-06,
      "loss": 1.1307,
      "step": 8800
    },
    {
      "epoch": 1.6799544419134396,
      "grad_norm": 8.083966255187988,
      "learning_rate": 3.3599088838268794e-06,
      "loss": 1.1504,
      "step": 8850
    },
    {
      "epoch": 1.689445709946849,
      "grad_norm": 8.695137023925781,
      "learning_rate": 3.378891419893698e-06,
      "loss": 1.0736,
      "step": 8900
    },
    {
      "epoch": 1.6989369779802581,
      "grad_norm": 8.855749130249023,
      "learning_rate": 3.397873955960517e-06,
      "loss": 1.1542,
      "step": 8950
    },
    {
      "epoch": 1.7084282460136673,
      "grad_norm": 20.272502899169922,
      "learning_rate": 3.416856492027335e-06,
      "loss": 1.096,
      "step": 9000
    },
    {
      "epoch": 1.7179195140470767,
      "grad_norm": 11.040966987609863,
      "learning_rate": 3.435839028094154e-06,
      "loss": 1.1346,
      "step": 9050
    },
    {
      "epoch": 1.727410782080486,
      "grad_norm": 5.113995552062988,
      "learning_rate": 3.454821564160972e-06,
      "loss": 1.1019,
      "step": 9100
    },
    {
      "epoch": 1.7369020501138952,
      "grad_norm": 11.643346786499023,
      "learning_rate": 3.4738041002277906e-06,
      "loss": 1.0748,
      "step": 9150
    },
    {
      "epoch": 1.7463933181473044,
      "grad_norm": 10.62111759185791,
      "learning_rate": 3.4927866362946096e-06,
      "loss": 1.1142,
      "step": 9200
    },
    {
      "epoch": 1.7558845861807137,
      "grad_norm": 8.423551559448242,
      "learning_rate": 3.5117691723614277e-06,
      "loss": 1.0018,
      "step": 9250
    },
    {
      "epoch": 1.7653758542141231,
      "grad_norm": 10.693641662597656,
      "learning_rate": 3.530751708428246e-06,
      "loss": 1.0869,
      "step": 9300
    },
    {
      "epoch": 1.7748671222475323,
      "grad_norm": 10.273809432983398,
      "learning_rate": 3.549734244495065e-06,
      "loss": 1.0726,
      "step": 9350
    },
    {
      "epoch": 1.7843583902809415,
      "grad_norm": 6.998386383056641,
      "learning_rate": 3.5687167805618832e-06,
      "loss": 1.1555,
      "step": 9400
    },
    {
      "epoch": 1.7938496583143508,
      "grad_norm": 6.818355083465576,
      "learning_rate": 3.5876993166287018e-06,
      "loss": 1.077,
      "step": 9450
    },
    {
      "epoch": 1.8033409263477602,
      "grad_norm": 12.327679634094238,
      "learning_rate": 3.6066818526955207e-06,
      "loss": 1.1372,
      "step": 9500
    },
    {
      "epoch": 1.8128321943811692,
      "grad_norm": 12.766919136047363,
      "learning_rate": 3.625664388762339e-06,
      "loss": 1.088,
      "step": 9550
    },
    {
      "epoch": 1.8223234624145785,
      "grad_norm": 7.449977397918701,
      "learning_rate": 3.6446469248291578e-06,
      "loss": 1.0675,
      "step": 9600
    },
    {
      "epoch": 1.831814730447988,
      "grad_norm": 11.831316947937012,
      "learning_rate": 3.663629460895976e-06,
      "loss": 1.1741,
      "step": 9650
    },
    {
      "epoch": 1.841305998481397,
      "grad_norm": 15.062392234802246,
      "learning_rate": 3.6826119969627944e-06,
      "loss": 1.0829,
      "step": 9700
    },
    {
      "epoch": 1.8507972665148062,
      "grad_norm": 6.773420810699463,
      "learning_rate": 3.7015945330296134e-06,
      "loss": 1.0558,
      "step": 9750
    },
    {
      "epoch": 1.8602885345482156,
      "grad_norm": 9.245349884033203,
      "learning_rate": 3.7205770690964315e-06,
      "loss": 1.118,
      "step": 9800
    },
    {
      "epoch": 1.869779802581625,
      "grad_norm": 16.190425872802734,
      "learning_rate": 3.73955960516325e-06,
      "loss": 0.98,
      "step": 9850
    },
    {
      "epoch": 1.8792710706150342,
      "grad_norm": 5.989975929260254,
      "learning_rate": 3.758542141230069e-06,
      "loss": 1.0671,
      "step": 9900
    },
    {
      "epoch": 1.8887623386484433,
      "grad_norm": 10.689846992492676,
      "learning_rate": 3.777524677296887e-06,
      "loss": 1.1324,
      "step": 9950
    },
    {
      "epoch": 1.8982536066818527,
      "grad_norm": 7.839616775512695,
      "learning_rate": 3.796507213363706e-06,
      "loss": 1.0502,
      "step": 10000
    },
    {
      "epoch": 1.907744874715262,
      "grad_norm": 11.228259086608887,
      "learning_rate": 3.815489749430524e-06,
      "loss": 1.0626,
      "step": 10050
    },
    {
      "epoch": 1.9172361427486713,
      "grad_norm": 8.731637001037598,
      "learning_rate": 3.834472285497343e-06,
      "loss": 1.0557,
      "step": 10100
    },
    {
      "epoch": 1.9267274107820804,
      "grad_norm": 7.369215488433838,
      "learning_rate": 3.853454821564161e-06,
      "loss": 1.0551,
      "step": 10150
    },
    {
      "epoch": 1.9362186788154898,
      "grad_norm": 13.776960372924805,
      "learning_rate": 3.87243735763098e-06,
      "loss": 0.9098,
      "step": 10200
    },
    {
      "epoch": 1.945709946848899,
      "grad_norm": 14.922910690307617,
      "learning_rate": 3.891419893697798e-06,
      "loss": 1.0094,
      "step": 10250
    },
    {
      "epoch": 1.9552012148823081,
      "grad_norm": 14.49189281463623,
      "learning_rate": 3.910402429764617e-06,
      "loss": 1.0408,
      "step": 10300
    },
    {
      "epoch": 1.9646924829157175,
      "grad_norm": 8.074590682983398,
      "learning_rate": 3.929384965831435e-06,
      "loss": 1.0013,
      "step": 10350
    },
    {
      "epoch": 1.974183750949127,
      "grad_norm": 13.741362571716309,
      "learning_rate": 3.948367501898254e-06,
      "loss": 1.0558,
      "step": 10400
    },
    {
      "epoch": 1.983675018982536,
      "grad_norm": 8.54836368560791,
      "learning_rate": 3.967350037965072e-06,
      "loss": 1.1325,
      "step": 10450
    },
    {
      "epoch": 1.9931662870159452,
      "grad_norm": 8.981844902038574,
      "learning_rate": 3.986332574031891e-06,
      "loss": 1.025,
      "step": 10500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.6111796526525577,
      "eval_f1": 0.3383157578598897,
      "eval_loss": 0.9857298731803894,
      "eval_precision": 0.32815693863098555,
      "eval_recall": 0.38700316043361305,
      "eval_runtime": 171.5949,
      "eval_samples_per_second": 61.406,
      "eval_steps_per_second": 7.681,
      "step": 10536
    }
  ],
  "logging_steps": 50,
  "max_steps": 263400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 417806483226624.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
