{
  "best_metric": 1.3035351037979126,
  "best_model_checkpoint": "./results\\checkpoint-5268",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 5268,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009491268033409264,
      "grad_norm": 6.781533718109131,
      "learning_rate": 1.8982536066818528e-08,
      "loss": 1.9045,
      "step": 50
    },
    {
      "epoch": 0.018982536066818528,
      "grad_norm": 7.266733646392822,
      "learning_rate": 3.7965072133637056e-08,
      "loss": 1.8964,
      "step": 100
    },
    {
      "epoch": 0.02847380410022779,
      "grad_norm": 7.532681941986084,
      "learning_rate": 5.694760820045559e-08,
      "loss": 1.9081,
      "step": 150
    },
    {
      "epoch": 0.037965072133637055,
      "grad_norm": 6.661933422088623,
      "learning_rate": 7.593014426727411e-08,
      "loss": 1.8962,
      "step": 200
    },
    {
      "epoch": 0.04745634016704632,
      "grad_norm": 4.782284259796143,
      "learning_rate": 9.491268033409265e-08,
      "loss": 1.9219,
      "step": 250
    },
    {
      "epoch": 0.05694760820045558,
      "grad_norm": 6.672574043273926,
      "learning_rate": 1.1389521640091118e-07,
      "loss": 1.8861,
      "step": 300
    },
    {
      "epoch": 0.06643887623386484,
      "grad_norm": 6.003439903259277,
      "learning_rate": 1.328777524677297e-07,
      "loss": 1.9094,
      "step": 350
    },
    {
      "epoch": 0.07593014426727411,
      "grad_norm": 6.052431583404541,
      "learning_rate": 1.5186028853454822e-07,
      "loss": 1.93,
      "step": 400
    },
    {
      "epoch": 0.08542141230068337,
      "grad_norm": 8.3948392868042,
      "learning_rate": 1.7084282460136675e-07,
      "loss": 1.9126,
      "step": 450
    },
    {
      "epoch": 0.09491268033409264,
      "grad_norm": 6.39821720123291,
      "learning_rate": 1.898253606681853e-07,
      "loss": 1.8955,
      "step": 500
    },
    {
      "epoch": 0.1044039483675019,
      "grad_norm": 6.71638298034668,
      "learning_rate": 2.0880789673500383e-07,
      "loss": 1.885,
      "step": 550
    },
    {
      "epoch": 0.11389521640091116,
      "grad_norm": 5.5600361824035645,
      "learning_rate": 2.2779043280182236e-07,
      "loss": 1.8805,
      "step": 600
    },
    {
      "epoch": 0.12338648443432043,
      "grad_norm": 8.162986755371094,
      "learning_rate": 2.4677296886864086e-07,
      "loss": 1.8604,
      "step": 650
    },
    {
      "epoch": 0.13287775246772968,
      "grad_norm": 6.437964916229248,
      "learning_rate": 2.657555049354594e-07,
      "loss": 1.88,
      "step": 700
    },
    {
      "epoch": 0.14236902050113895,
      "grad_norm": 6.0843186378479,
      "learning_rate": 2.847380410022779e-07,
      "loss": 1.8939,
      "step": 750
    },
    {
      "epoch": 0.15186028853454822,
      "grad_norm": 6.881246566772461,
      "learning_rate": 3.0372057706909645e-07,
      "loss": 1.8767,
      "step": 800
    },
    {
      "epoch": 0.16135155656795747,
      "grad_norm": 7.419300556182861,
      "learning_rate": 3.22703113135915e-07,
      "loss": 1.8718,
      "step": 850
    },
    {
      "epoch": 0.17084282460136674,
      "grad_norm": 5.736841678619385,
      "learning_rate": 3.416856492027335e-07,
      "loss": 1.8611,
      "step": 900
    },
    {
      "epoch": 0.180334092634776,
      "grad_norm": 6.552237033843994,
      "learning_rate": 3.6066818526955203e-07,
      "loss": 1.8646,
      "step": 950
    },
    {
      "epoch": 0.18982536066818528,
      "grad_norm": 7.06653356552124,
      "learning_rate": 3.796507213363706e-07,
      "loss": 1.8617,
      "step": 1000
    },
    {
      "epoch": 0.19931662870159453,
      "grad_norm": 6.590609073638916,
      "learning_rate": 3.9863325740318914e-07,
      "loss": 1.8511,
      "step": 1050
    },
    {
      "epoch": 0.2088078967350038,
      "grad_norm": 8.35180950164795,
      "learning_rate": 4.1761579347000767e-07,
      "loss": 1.8463,
      "step": 1100
    },
    {
      "epoch": 0.21829916476841307,
      "grad_norm": 7.201739311218262,
      "learning_rate": 4.365983295368262e-07,
      "loss": 1.8574,
      "step": 1150
    },
    {
      "epoch": 0.22779043280182232,
      "grad_norm": 6.361911773681641,
      "learning_rate": 4.555808656036447e-07,
      "loss": 1.8475,
      "step": 1200
    },
    {
      "epoch": 0.2372817008352316,
      "grad_norm": 8.124828338623047,
      "learning_rate": 4.7456340167046325e-07,
      "loss": 1.8672,
      "step": 1250
    },
    {
      "epoch": 0.24677296886864086,
      "grad_norm": 7.5856804847717285,
      "learning_rate": 4.935459377372817e-07,
      "loss": 1.8176,
      "step": 1300
    },
    {
      "epoch": 0.25626423690205014,
      "grad_norm": 5.980137825012207,
      "learning_rate": 5.125284738041003e-07,
      "loss": 1.8091,
      "step": 1350
    },
    {
      "epoch": 0.26575550493545935,
      "grad_norm": 7.428492069244385,
      "learning_rate": 5.315110098709188e-07,
      "loss": 1.8369,
      "step": 1400
    },
    {
      "epoch": 0.2752467729688686,
      "grad_norm": 6.454822063446045,
      "learning_rate": 5.504935459377373e-07,
      "loss": 1.8164,
      "step": 1450
    },
    {
      "epoch": 0.2847380410022779,
      "grad_norm": 6.958491325378418,
      "learning_rate": 5.694760820045558e-07,
      "loss": 1.7924,
      "step": 1500
    },
    {
      "epoch": 0.29422930903568717,
      "grad_norm": 6.073852062225342,
      "learning_rate": 5.884586180713744e-07,
      "loss": 1.7821,
      "step": 1550
    },
    {
      "epoch": 0.30372057706909644,
      "grad_norm": 6.060319423675537,
      "learning_rate": 6.074411541381929e-07,
      "loss": 1.8076,
      "step": 1600
    },
    {
      "epoch": 0.3132118451025057,
      "grad_norm": 6.922138214111328,
      "learning_rate": 6.264236902050115e-07,
      "loss": 1.7945,
      "step": 1650
    },
    {
      "epoch": 0.32270311313591493,
      "grad_norm": 8.807982444763184,
      "learning_rate": 6.4540622627183e-07,
      "loss": 1.7946,
      "step": 1700
    },
    {
      "epoch": 0.3321943811693242,
      "grad_norm": 8.394856452941895,
      "learning_rate": 6.643887623386485e-07,
      "loss": 1.7592,
      "step": 1750
    },
    {
      "epoch": 0.3416856492027335,
      "grad_norm": 7.335812568664551,
      "learning_rate": 6.83371298405467e-07,
      "loss": 1.7673,
      "step": 1800
    },
    {
      "epoch": 0.35117691723614275,
      "grad_norm": 5.55386209487915,
      "learning_rate": 7.023538344722855e-07,
      "loss": 1.7621,
      "step": 1850
    },
    {
      "epoch": 0.360668185269552,
      "grad_norm": 6.270002841949463,
      "learning_rate": 7.213363705391041e-07,
      "loss": 1.7644,
      "step": 1900
    },
    {
      "epoch": 0.3701594533029613,
      "grad_norm": 6.1040472984313965,
      "learning_rate": 7.403189066059226e-07,
      "loss": 1.742,
      "step": 1950
    },
    {
      "epoch": 0.37965072133637057,
      "grad_norm": 7.086050987243652,
      "learning_rate": 7.593014426727412e-07,
      "loss": 1.7636,
      "step": 2000
    },
    {
      "epoch": 0.3891419893697798,
      "grad_norm": 6.752301216125488,
      "learning_rate": 7.782839787395596e-07,
      "loss": 1.7136,
      "step": 2050
    },
    {
      "epoch": 0.39863325740318906,
      "grad_norm": 7.262324333190918,
      "learning_rate": 7.972665148063783e-07,
      "loss": 1.7126,
      "step": 2100
    },
    {
      "epoch": 0.40812452543659833,
      "grad_norm": 6.354671478271484,
      "learning_rate": 8.162490508731967e-07,
      "loss": 1.768,
      "step": 2150
    },
    {
      "epoch": 0.4176157934700076,
      "grad_norm": 6.536283016204834,
      "learning_rate": 8.352315869400153e-07,
      "loss": 1.7133,
      "step": 2200
    },
    {
      "epoch": 0.4271070615034169,
      "grad_norm": 5.915724277496338,
      "learning_rate": 8.542141230068338e-07,
      "loss": 1.6628,
      "step": 2250
    },
    {
      "epoch": 0.43659832953682615,
      "grad_norm": 6.443665981292725,
      "learning_rate": 8.731966590736524e-07,
      "loss": 1.6854,
      "step": 2300
    },
    {
      "epoch": 0.44608959757023536,
      "grad_norm": 6.667612552642822,
      "learning_rate": 8.921791951404708e-07,
      "loss": 1.6875,
      "step": 2350
    },
    {
      "epoch": 0.45558086560364464,
      "grad_norm": 5.933440208435059,
      "learning_rate": 9.111617312072894e-07,
      "loss": 1.6823,
      "step": 2400
    },
    {
      "epoch": 0.4650721336370539,
      "grad_norm": 5.7874932289123535,
      "learning_rate": 9.301442672741079e-07,
      "loss": 1.6848,
      "step": 2450
    },
    {
      "epoch": 0.4745634016704632,
      "grad_norm": 6.891671180725098,
      "learning_rate": 9.491268033409265e-07,
      "loss": 1.665,
      "step": 2500
    },
    {
      "epoch": 0.48405466970387245,
      "grad_norm": 6.06433629989624,
      "learning_rate": 9.68109339407745e-07,
      "loss": 1.6278,
      "step": 2550
    },
    {
      "epoch": 0.4935459377372817,
      "grad_norm": 6.95818567276001,
      "learning_rate": 9.870918754745634e-07,
      "loss": 1.6393,
      "step": 2600
    },
    {
      "epoch": 0.503037205770691,
      "grad_norm": 6.200324535369873,
      "learning_rate": 1.006074411541382e-06,
      "loss": 1.6185,
      "step": 2650
    },
    {
      "epoch": 0.5125284738041003,
      "grad_norm": 6.010601043701172,
      "learning_rate": 1.0250569476082005e-06,
      "loss": 1.5811,
      "step": 2700
    },
    {
      "epoch": 0.5220197418375095,
      "grad_norm": 8.4634428024292,
      "learning_rate": 1.044039483675019e-06,
      "loss": 1.599,
      "step": 2750
    },
    {
      "epoch": 0.5315110098709187,
      "grad_norm": 5.99493408203125,
      "learning_rate": 1.0630220197418376e-06,
      "loss": 1.6122,
      "step": 2800
    },
    {
      "epoch": 0.541002277904328,
      "grad_norm": 5.33767032623291,
      "learning_rate": 1.082004555808656e-06,
      "loss": 1.6236,
      "step": 2850
    },
    {
      "epoch": 0.5504935459377372,
      "grad_norm": 5.12007999420166,
      "learning_rate": 1.1009870918754746e-06,
      "loss": 1.604,
      "step": 2900
    },
    {
      "epoch": 0.5599848139711465,
      "grad_norm": 6.034331321716309,
      "learning_rate": 1.1199696279422931e-06,
      "loss": 1.6182,
      "step": 2950
    },
    {
      "epoch": 0.5694760820045558,
      "grad_norm": 5.838982582092285,
      "learning_rate": 1.1389521640091117e-06,
      "loss": 1.5432,
      "step": 3000
    },
    {
      "epoch": 0.5789673500379651,
      "grad_norm": 5.8897223472595215,
      "learning_rate": 1.1579347000759302e-06,
      "loss": 1.5486,
      "step": 3050
    },
    {
      "epoch": 0.5884586180713743,
      "grad_norm": 5.698884963989258,
      "learning_rate": 1.1769172361427487e-06,
      "loss": 1.5531,
      "step": 3100
    },
    {
      "epoch": 0.5979498861047836,
      "grad_norm": 6.753091335296631,
      "learning_rate": 1.1958997722095673e-06,
      "loss": 1.526,
      "step": 3150
    },
    {
      "epoch": 0.6074411541381929,
      "grad_norm": 5.610910415649414,
      "learning_rate": 1.2148823082763858e-06,
      "loss": 1.497,
      "step": 3200
    },
    {
      "epoch": 0.6169324221716022,
      "grad_norm": 5.57576847076416,
      "learning_rate": 1.2338648443432043e-06,
      "loss": 1.4717,
      "step": 3250
    },
    {
      "epoch": 0.6264236902050114,
      "grad_norm": 5.431122303009033,
      "learning_rate": 1.252847380410023e-06,
      "loss": 1.5459,
      "step": 3300
    },
    {
      "epoch": 0.6359149582384207,
      "grad_norm": 5.800791263580322,
      "learning_rate": 1.2718299164768414e-06,
      "loss": 1.4849,
      "step": 3350
    },
    {
      "epoch": 0.6454062262718299,
      "grad_norm": 6.740391254425049,
      "learning_rate": 1.29081245254366e-06,
      "loss": 1.547,
      "step": 3400
    },
    {
      "epoch": 0.6548974943052391,
      "grad_norm": 6.926745414733887,
      "learning_rate": 1.3097949886104786e-06,
      "loss": 1.6048,
      "step": 3450
    },
    {
      "epoch": 0.6643887623386484,
      "grad_norm": 6.111976146697998,
      "learning_rate": 1.328777524677297e-06,
      "loss": 1.5252,
      "step": 3500
    },
    {
      "epoch": 0.6738800303720577,
      "grad_norm": 7.135305881500244,
      "learning_rate": 1.3477600607441155e-06,
      "loss": 1.5267,
      "step": 3550
    },
    {
      "epoch": 0.683371298405467,
      "grad_norm": 6.208704948425293,
      "learning_rate": 1.366742596810934e-06,
      "loss": 1.4807,
      "step": 3600
    },
    {
      "epoch": 0.6928625664388762,
      "grad_norm": 7.233537673950195,
      "learning_rate": 1.3857251328777527e-06,
      "loss": 1.5276,
      "step": 3650
    },
    {
      "epoch": 0.7023538344722855,
      "grad_norm": 5.419264793395996,
      "learning_rate": 1.404707668944571e-06,
      "loss": 1.4692,
      "step": 3700
    },
    {
      "epoch": 0.7118451025056948,
      "grad_norm": 5.498508453369141,
      "learning_rate": 1.4236902050113896e-06,
      "loss": 1.4666,
      "step": 3750
    },
    {
      "epoch": 0.721336370539104,
      "grad_norm": 5.954653263092041,
      "learning_rate": 1.4426727410782081e-06,
      "loss": 1.4721,
      "step": 3800
    },
    {
      "epoch": 0.7308276385725133,
      "grad_norm": 5.4256205558776855,
      "learning_rate": 1.4616552771450269e-06,
      "loss": 1.4695,
      "step": 3850
    },
    {
      "epoch": 0.7403189066059226,
      "grad_norm": 5.338573932647705,
      "learning_rate": 1.4806378132118452e-06,
      "loss": 1.498,
      "step": 3900
    },
    {
      "epoch": 0.7498101746393319,
      "grad_norm": 5.638768672943115,
      "learning_rate": 1.4996203492786637e-06,
      "loss": 1.4868,
      "step": 3950
    },
    {
      "epoch": 0.7593014426727411,
      "grad_norm": 6.837031364440918,
      "learning_rate": 1.5186028853454824e-06,
      "loss": 1.4734,
      "step": 4000
    },
    {
      "epoch": 0.7687927107061503,
      "grad_norm": 5.757120609283447,
      "learning_rate": 1.537585421412301e-06,
      "loss": 1.4525,
      "step": 4050
    },
    {
      "epoch": 0.7782839787395596,
      "grad_norm": 4.101736068725586,
      "learning_rate": 1.5565679574791193e-06,
      "loss": 1.4537,
      "step": 4100
    },
    {
      "epoch": 0.7877752467729688,
      "grad_norm": 5.155644416809082,
      "learning_rate": 1.5755504935459378e-06,
      "loss": 1.4402,
      "step": 4150
    },
    {
      "epoch": 0.7972665148063781,
      "grad_norm": 5.0357770919799805,
      "learning_rate": 1.5945330296127566e-06,
      "loss": 1.3498,
      "step": 4200
    },
    {
      "epoch": 0.8067577828397874,
      "grad_norm": 5.147688388824463,
      "learning_rate": 1.6135155656795749e-06,
      "loss": 1.4572,
      "step": 4250
    },
    {
      "epoch": 0.8162490508731967,
      "grad_norm": 8.150679588317871,
      "learning_rate": 1.6324981017463934e-06,
      "loss": 1.4161,
      "step": 4300
    },
    {
      "epoch": 0.8257403189066059,
      "grad_norm": 5.87668514251709,
      "learning_rate": 1.651480637813212e-06,
      "loss": 1.45,
      "step": 4350
    },
    {
      "epoch": 0.8352315869400152,
      "grad_norm": 6.621004104614258,
      "learning_rate": 1.6704631738800307e-06,
      "loss": 1.4432,
      "step": 4400
    },
    {
      "epoch": 0.8447228549734245,
      "grad_norm": 5.4572649002075195,
      "learning_rate": 1.689445709946849e-06,
      "loss": 1.4434,
      "step": 4450
    },
    {
      "epoch": 0.8542141230068337,
      "grad_norm": 5.729280948638916,
      "learning_rate": 1.7084282460136675e-06,
      "loss": 1.4217,
      "step": 4500
    },
    {
      "epoch": 0.863705391040243,
      "grad_norm": 6.268518447875977,
      "learning_rate": 1.727410782080486e-06,
      "loss": 1.3319,
      "step": 4550
    },
    {
      "epoch": 0.8731966590736523,
      "grad_norm": 5.37209939956665,
      "learning_rate": 1.7463933181473048e-06,
      "loss": 1.4134,
      "step": 4600
    },
    {
      "epoch": 0.8826879271070615,
      "grad_norm": 5.681509494781494,
      "learning_rate": 1.765375854214123e-06,
      "loss": 1.4411,
      "step": 4650
    },
    {
      "epoch": 0.8921791951404707,
      "grad_norm": 5.10499382019043,
      "learning_rate": 1.7843583902809416e-06,
      "loss": 1.3592,
      "step": 4700
    },
    {
      "epoch": 0.90167046317388,
      "grad_norm": 5.10657262802124,
      "learning_rate": 1.8033409263477604e-06,
      "loss": 1.3716,
      "step": 4750
    },
    {
      "epoch": 0.9111617312072893,
      "grad_norm": 5.1439666748046875,
      "learning_rate": 1.8223234624145789e-06,
      "loss": 1.3919,
      "step": 4800
    },
    {
      "epoch": 0.9206529992406985,
      "grad_norm": 6.941906452178955,
      "learning_rate": 1.8413059984813972e-06,
      "loss": 1.3528,
      "step": 4850
    },
    {
      "epoch": 0.9301442672741078,
      "grad_norm": 4.646480560302734,
      "learning_rate": 1.8602885345482157e-06,
      "loss": 1.3679,
      "step": 4900
    },
    {
      "epoch": 0.9396355353075171,
      "grad_norm": 4.150309085845947,
      "learning_rate": 1.8792710706150345e-06,
      "loss": 1.354,
      "step": 4950
    },
    {
      "epoch": 0.9491268033409264,
      "grad_norm": 6.288318157196045,
      "learning_rate": 1.898253606681853e-06,
      "loss": 1.4323,
      "step": 5000
    },
    {
      "epoch": 0.9586180713743356,
      "grad_norm": 5.229976177215576,
      "learning_rate": 1.9172361427486713e-06,
      "loss": 1.3896,
      "step": 5050
    },
    {
      "epoch": 0.9681093394077449,
      "grad_norm": 5.8981852531433105,
      "learning_rate": 1.93621867881549e-06,
      "loss": 1.3476,
      "step": 5100
    },
    {
      "epoch": 0.9776006074411542,
      "grad_norm": 7.595494747161865,
      "learning_rate": 1.9552012148823084e-06,
      "loss": 1.4024,
      "step": 5150
    },
    {
      "epoch": 0.9870918754745635,
      "grad_norm": 7.758345127105713,
      "learning_rate": 1.974183750949127e-06,
      "loss": 1.3631,
      "step": 5200
    },
    {
      "epoch": 0.9965831435079726,
      "grad_norm": 5.87869930267334,
      "learning_rate": 1.9931662870159454e-06,
      "loss": 1.3904,
      "step": 5250
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5406662237828604,
      "eval_f1": 0.19993373817835974,
      "eval_loss": 1.3035351037979126,
      "eval_precision": 0.3118988727776137,
      "eval_recall": 0.257349917072959,
      "eval_runtime": 190.9898,
      "eval_samples_per_second": 55.17,
      "eval_steps_per_second": 6.901,
      "step": 5268
    }
  ],
  "logging_steps": 50,
  "max_steps": 263400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 208903241613312.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
